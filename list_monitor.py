#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç‰¹åˆ—è¡¨ç›‘å¬è„šæœ¬
ç›‘å¬æŒ‡å®šæ¨ç‰¹åˆ—è¡¨ä¸­çš„æ–°æ¨æ–‡ï¼Œå¹¶é€šè¿‡webhookæ¨é€
"""

import re
import time
import os
import requests
import random
import json
import asyncio
import base64
from datetime import datetime
from io import BytesIO
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException

# å¯¼å…¥é…ç½®å’Œwebhookæ¨¡å—
try:
    from config import (
        CHROME_PROXY, USE_PERSISTENT_PROFILE, PROFILE_DIR,
        PUSHED_IDS_FILE, LIST_CHECK_INTERVAL, MAX_TWEETS_PER_CHECK
    )
    from webhook import send_message_async, send_image_async
except ImportError as e:
    print(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ config.py å’Œ webhook.py æ–‡ä»¶å­˜åœ¨")
    exit(1)

# ==================== é…ç½®åŒºåŸŸ ====================
# è¦ç›‘å¬çš„æ¨ç‰¹åˆ—è¡¨URLï¼ˆå¯ä»¥é…ç½®å¤šä¸ªï¼‰
TWITTER_LISTS = [
    "https://x.com/i/lists/1876489130466816018"  # æµ‹è¯•åˆ—è¡¨
]

# è¦ç›‘å¬çš„ç”¨æˆ·ç™½åå•ï¼ˆåªæ¨é€è¿™äº›ç”¨æˆ·çš„æ¨æ–‡ï¼‰
# æ ¼å¼ï¼šç”¨æˆ·åï¼ˆä¸å«@ç¬¦å·ï¼‰ï¼Œä¾‹å¦‚ "elonmusk", "0xSunNFT"
# å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œåˆ™æ¨é€æ‰€æœ‰ç”¨æˆ·çš„æ¨æ–‡
MONITORED_USERS = [
    'pepeboost888',
    'Arya_web3',    
    'web3feng',
    'cryptoDevinL',
    'brc20niubi',
    '0xcryptowizard',
    '0xcryptocishanjia',
    '0xsunnft',
]

# æ˜¯å¦å¯ç”¨ç”¨æˆ·ç™½åå•è¿‡æ»¤ï¼ˆTrue=åªæ¨é€ç™½åå•ç”¨æˆ·ï¼ŒFalse=æ¨é€æ‰€æœ‰ç”¨æˆ·ï¼‰
ENABLE_USER_FILTER = True

# ==================== è¾…åŠ©å‡½æ•° ====================
def load_pushed_ids():
    """åŠ è½½å·²æ¨é€çš„æ¨æ–‡ID"""
    if os.path.exists(PUSHED_IDS_FILE):
        try:
            with open(PUSHED_IDS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_pushed_id(tweet_id):
    """ä¿å­˜å·²æ¨é€çš„æ¨æ–‡ID"""
    pushed_ids = load_pushed_ids()
    pushed_ids.add(tweet_id)
    with open(PUSHED_IDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(pushed_ids), f, indent=2)

def random_sleep(min_sec=2, max_sec=5):
    """éšæœºå»¶æ—¶ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
    sleep_time = random.uniform(min_sec, max_sec)
    print(f"  éšæœºç­‰å¾… {sleep_time:.2f} ç§’...")
    time.sleep(sleep_time)

def create_undetected_driver():
    """åˆ›å»ºåæ£€æµ‹çš„Chromeæµè§ˆå™¨å®ä¾‹"""
    print("æ­£åœ¨å¯åŠ¨ undetected_chromedriver...")
    
    options = uc.ChromeOptions()
    
    # æ·»åŠ ä»£ç†é…ç½®
    if CHROME_PROXY:
        print(f"  é…ç½®ä»£ç†: {CHROME_PROXY}")
        options.add_argument(f'--proxy-server={CHROME_PROXY}')
    
    # ä½¿ç”¨æŒä¹…åŒ–Profile
    if USE_PERSISTENT_PROFILE:
        print(f"  ä½¿ç”¨æŒä¹…åŒ–Profile: {PROFILE_DIR}")
        options.add_argument(f'--user-data-dir={PROFILE_DIR}')
    
    # å…¶ä»–ä¼˜åŒ–é€‰é¡¹
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    
    try:
        driver = uc.Chrome(options=options)
        print("âœ“ undetected_chromedriver å¯åŠ¨æˆåŠŸ")
        return driver
    except Exception as e:
        print(f"Ã— å¯åŠ¨å¤±è´¥: {e}")
        raise

def download_image_to_base64(url, proxy=None):
    """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64ç¼–ç 
    
    Args:
        url: å›¾ç‰‡URL
        proxy: ä»£ç†é…ç½®
    
    Returns:
        str: base64ç¼–ç çš„å›¾ç‰‡ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        proxies = {'http': proxy, 'https': proxy} if proxy else None
        
        response = requests.get(url, headers=headers, proxies=proxies, timeout=15)
        if response.status_code == 200:
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            return image_base64
        else:
            print(f"  Ã— ä¸‹è½½å›¾ç‰‡å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
            return None
    except Exception as e:
        print(f"  Ã— ä¸‹è½½å›¾ç‰‡å¼‚å¸¸: {e}")
        return None

def extract_tweet_data(tweet_article):
    """ä»æ¨æ–‡å…ƒç´ ä¸­æå–æ•°æ®
    
    Args:
        tweet_article: Selenium WebElementï¼Œæ¨æ–‡çš„articleå…ƒç´ 
        
    Returns:
        dict: åŒ…å«æ¨æ–‡æ•°æ®çš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        # æå–æ¨æ–‡IDå’ŒURL
        tweet_link_elements = tweet_article.find_elements(By.XPATH, ".//a[contains(@href, '/status/')]")
        tweet_url = None
        tweet_id = None
        
        for link in tweet_link_elements:
            href = link.get_attribute('href')
            if '/status/' in href and '/analytics' not in href:  # æ’é™¤analyticsé“¾æ¥
                tweet_url = href
                # æ¸…ç†URLï¼Œç§»é™¤é¢å¤–çš„è·¯å¾„
                tweet_id = href.split('/status/')[-1].split('?')[0].split('/')[0]
                break
        
        if not tweet_id:
            return None
        
        # æå–æ¨æ–‡æ­£æ–‡
        tweet_text = ""
        try:
            tweet_text_element = tweet_article.find_element(By.XPATH, ".//div[@data-testid='tweetText']")
            tweet_text = tweet_text_element.text
        except NoSuchElementException:
            pass
        
        # æå–ç”¨æˆ·åå’Œæ˜¾ç¤ºåç§°
        user_handle = ""
        user_handle_raw = ""  # ä¸å¸¦@çš„ç”¨æˆ·å
        user_display_name = ""
        try:
            user_name_div = tweet_article.find_element(By.XPATH, ".//div[@data-testid='User-Name']")
            # æå–æ˜¾ç¤ºåç§°
            try:
                display_name_element = user_name_div.find_element(By.XPATH, ".//span[contains(@class, 'css-1jxf684')]")
                user_display_name = display_name_element.text
            except:
                pass
            
            # æå–handle (@username)
            try:
                handle_element = user_name_div.find_element(By.XPATH, ".//a[contains(@href, '/')]")
                user_handle_raw = handle_element.get_attribute('href').split('/')[-1].split('?')[0]
                user_handle = f"@{user_handle_raw}"
            except:
                pass
        except NoSuchElementException:
            pass
        
        # æå–æ¨æ–‡æ—¶é—´
        tweet_time = ""
        try:
            time_element = tweet_article.find_element(By.XPATH, ".//time")
            tweet_time = time_element.get_attribute('datetime')
            # æ ¼å¼åŒ–æ—¶é—´ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
            if tweet_time:
                dt = datetime.fromisoformat(tweet_time.replace('Z', '+00:00'))
                tweet_time = dt.strftime('%Y-%m-%d %H:%M:%S')
        except NoSuchElementException:
            pass
        
        # æå–å›¾ç‰‡URL
        image_urls = []
        try:
            photo_divs = tweet_article.find_elements(By.XPATH, ".//div[@data-testid='tweetPhoto']")
            
            for photo_div in photo_divs:
                img_elements = photo_div.find_elements(By.TAG_NAME, "img")
                for img_element in img_elements:
                    img_url = img_element.get_attribute('src')
                    
                    if img_url:
                        # å°†URLå‚æ•°æ›¿æ¢ä¸º 'name=orig' æ¥è·å–æœ€é«˜æ¸…çš„åŸå›¾
                        if 'name=' in img_url:
                            orig_img_url = re.sub(r'name=\w+', 'name=orig', img_url)
                        else:
                            orig_img_url = img_url.split('?')[0] + '?format=jpg&name=orig'
                        
                        if orig_img_url not in image_urls:
                            image_urls.append(orig_img_url)
        except:
            pass
        
        return {
            "id": tweet_id,
            "url": tweet_url,
            "handle": user_handle,
            "handle_raw": user_handle_raw,  # ä¸å¸¦@çš„ç”¨æˆ·åï¼Œç”¨äºè¿‡æ»¤
            "display_name": user_display_name,
            "time": tweet_time,
            "text": tweet_text,
            "images": image_urls
        }
    except Exception as e:
        print(f"  Ã— æå–æ¨æ–‡æ•°æ®å¤±è´¥: {e}")
        return None

async def send_tweet_to_webhook(tweet_data):
    """å°†æ¨æ–‡æ•°æ®å‘é€åˆ°webhook
    
    Args:
        tweet_data: æ¨æ–‡æ•°æ®å­—å…¸
    """
    try:
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_parts = []
        message_parts.append(f"ğŸ¦ æ–°æ¨æ–‡ç›‘å¬")
        message_parts.append(f"")
        
        # ç”¨æˆ·ä¿¡æ¯
        if tweet_data['display_name']:
            message_parts.append(f"ğŸ‘¤ ä½œè€…: {tweet_data['display_name']} ({tweet_data['handle']})")
        else:
            message_parts.append(f"ğŸ‘¤ ä½œè€…: {tweet_data['handle']}")
        
        # æ—¶é—´
        if tweet_data['time']:
            message_parts.append(f"ğŸ• æ—¶é—´: {tweet_data['time']}")
        
        # æ¨æ–‡é“¾æ¥
        if tweet_data['url']:
            message_parts.append(f"ğŸ”— é“¾æ¥: {tweet_data['url']}")
        
        message_parts.append(f"")
        
        # æ¨æ–‡å†…å®¹
        if tweet_data['text']:
            message_parts.append(f"ğŸ“ å†…å®¹:")
            message_parts.append(tweet_data['text'])
            message_parts.append(f"")
        
        # å›¾ç‰‡ä¿¡æ¯
        if tweet_data['images']:
            message_parts.append(f"ğŸ–¼ï¸ åŒ…å« {len(tweet_data['images'])} å¼ å›¾ç‰‡")
        
        # å‘é€æ–‡æœ¬æ¶ˆæ¯
        message = "\n".join(message_parts)
        print(f"  å‘é€æ¨æ–‡é€šçŸ¥... {message}")
        await send_message_async(message, msg_type="text")
        
        # å‘é€å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if tweet_data['images']:
            print(f"  å‡†å¤‡å‘é€ {len(tweet_data['images'])} å¼ å›¾ç‰‡...")
            for idx, img_url in enumerate(tweet_data['images'], 1):
                print(f"  ä¸‹è½½å›¾ç‰‡ {idx}/{len(tweet_data['images'])}...")
                
                # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                proxy = CHROME_PROXY if CHROME_PROXY else None
                image_base64 = download_image_to_base64(img_url, proxy)
                
                if image_base64:
                    print(f"  å‘é€å›¾ç‰‡ {idx}/{len(tweet_data['images'])}...")
                    success = await send_image_async(image_base64=image_base64)
                    if success:
                        print(f"  âœ“ å›¾ç‰‡ {idx} å‘é€æˆåŠŸ")
                    else:
                        print(f"  Ã— å›¾ç‰‡ {idx} å‘é€å¤±è´¥")
                    
                    # å›¾ç‰‡å‘é€é—´éš”
                    if idx < len(tweet_data['images']):
                        await asyncio.sleep(1)
                else:
                    print(f"  Ã— å›¾ç‰‡ {idx} ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡")
        
        print(f"âœ“ æ¨æ–‡æ¨é€å®Œæˆ: {tweet_data['id']}")
        return True
        
    except Exception as e:
        print(f"Ã— æ¨é€æ¨æ–‡å¤±è´¥: {e}")
        return False

def is_user_in_whitelist(user_handle_raw):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­
    
    Args:
        user_handle_raw: ç”¨æˆ·åï¼ˆä¸å«@ï¼‰
        
    Returns:
        bool: å¦‚æœç”¨æˆ·åœ¨ç™½åå•æˆ–æœªå¯ç”¨è¿‡æ»¤ï¼Œè¿”å›True
    """
    # å¦‚æœæœªå¯ç”¨ç”¨æˆ·è¿‡æ»¤ï¼Œè¿”å›Trueï¼ˆå…è®¸æ‰€æœ‰ç”¨æˆ·ï¼‰
    if not ENABLE_USER_FILTER:
        return True
    
    # å¦‚æœç™½åå•ä¸ºç©ºï¼Œè¿”å›Trueï¼ˆå…è®¸æ‰€æœ‰ç”¨æˆ·ï¼‰
    if not MONITORED_USERS:
        return True
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    return user_handle_raw.lower() in [u.lower() for u in MONITORED_USERS]

def scrape_list_tweets(driver, list_url, max_tweets=20):
    """æŠ“å–æ¨ç‰¹åˆ—è¡¨ä¸­çš„æ¨æ–‡
    
    Args:
        driver: Selenium WebDriverå®ä¾‹
        list_url: æ¨ç‰¹åˆ—è¡¨URL
        max_tweets: æœ€å¤šæŠ“å–çš„æ¨æ–‡æ•°é‡
        
    Returns:
        list: æ¨æ–‡æ•°æ®åˆ—è¡¨
    """
    print(f"\nè®¿é—®åˆ—è¡¨: {list_url}")
    
    try:
        driver.get(list_url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        wait = WebDriverWait(driver, 15)
        
        # ç­‰å¾…æ¨æ–‡åŠ è½½
        print("  ç­‰å¾…æ¨æ–‡åŠ è½½...")
        time.sleep(5)
        
        tweets_data = []
        processed_ids = set()
        no_new_tweets_count = 0  # è¿ç»­æœªå‘ç°æ–°æ¨æ–‡çš„æ¬¡æ•°
        max_no_new_tweets = 3     # æœ€å¤šå…è®¸3æ¬¡æœªå‘ç°æ–°æ¨æ–‡
        
        # å…ˆè·å–å½“å‰å¯è§çš„æ¨æ–‡ï¼ˆä¸æ»šåŠ¨ï¼‰
        print("  æŠ“å–å½“å‰å¯è§æ¨æ–‡...")
        tweet_articles = driver.find_elements(By.XPATH, "//article[@data-testid='tweet']")
        print(f"  æ‰¾åˆ° {len(tweet_articles)} æ¡å¯è§æ¨æ–‡")
        
        for article in tweet_articles:
            if len(tweets_data) >= max_tweets:
                break
            
            tweet_data = extract_tweet_data(article)
            
            if tweet_data and tweet_data['id'] not in processed_ids:
                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­
                if is_user_in_whitelist(tweet_data['handle_raw']):
                    processed_ids.add(tweet_data['id'])
                    tweets_data.append(tweet_data)
                    print(f"  âœ“ æå–æ¨æ–‡: {tweet_data['handle']} - {tweet_data['id']}")
                else:
                    print(f"  âŠ˜ è·³è¿‡æ¨æ–‡ï¼ˆç”¨æˆ·ä¸åœ¨ç™½åå•ï¼‰: {tweet_data['handle']}")
        
        # å¦‚æœéœ€è¦æ›´å¤šæ¨æ–‡ï¼Œæ‰è¿›è¡Œæ»šåŠ¨
        if len(tweets_data) < max_tweets:
            print(f"  å½“å‰è·å– {len(tweets_data)} æ¡ï¼Œéœ€è¦æ›´å¤šæ¨æ–‡ï¼Œå¼€å§‹æ»šåŠ¨...")
            
            while len(tweets_data) < max_tweets and no_new_tweets_count < max_no_new_tweets:
                # è®°å½•æ»šåŠ¨å‰çš„æ¨æ–‡æ•°é‡
                before_scroll_count = len(tweets_data)
                
                # æ»šåŠ¨é¡µé¢
                driver.execute_script("window.scrollBy(0, 800);")  # æ¯æ¬¡åªæ»šåŠ¨800åƒç´ ï¼Œé¿å…è·³è¿‡å†…å®¹
                time.sleep(2)
                
                # è·å–æ–°å‡ºç°çš„æ¨æ–‡
                tweet_articles = driver.find_elements(By.XPATH, "//article[@data-testid='tweet']")
                
                # æå–æ–°æ¨æ–‡
                for article in tweet_articles:
                    if len(tweets_data) >= max_tweets:
                        break
                    
                    tweet_data = extract_tweet_data(article)
                    
                    if tweet_data and tweet_data['id'] not in processed_ids:
                        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­
                        if is_user_in_whitelist(tweet_data['handle_raw']):
                            processed_ids.add(tweet_data['id'])
                            tweets_data.append(tweet_data)
                            print(f"  âœ“ æå–æ¨æ–‡: {tweet_data['handle']} - {tweet_data['id']}")
                        else:
                            # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œä½†ä¸æ·»åŠ åˆ°ç»“æœä¸­
                            processed_ids.add(tweet_data['id'])
                            print(f"  âŠ˜ è·³è¿‡æ¨æ–‡ï¼ˆç”¨æˆ·ä¸åœ¨ç™½åå•ï¼‰: {tweet_data['handle']}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¨æ–‡
                if len(tweets_data) == before_scroll_count:
                    no_new_tweets_count += 1
                    print(f"  âš  æœªå‘ç°æ–°çš„ç¬¦åˆæ¡ä»¶çš„æ¨æ–‡ ({no_new_tweets_count}/{max_no_new_tweets})")
                else:
                    no_new_tweets_count = 0  # é‡ç½®è®¡æ•°å™¨
                    print(f"  å·²è·å– {len(tweets_data)}/{max_tweets} æ¡æ¨æ–‡")
        
        print(f"âœ“ å…±æå– {len(tweets_data)} æ¡æ¨æ–‡")
        
        # å¦‚æœå¯ç”¨äº†ç”¨æˆ·è¿‡æ»¤ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if ENABLE_USER_FILTER and MONITORED_USERS:
            print(f"  å·²å¯ç”¨ç”¨æˆ·ç™½åå•è¿‡æ»¤ï¼Œç›‘å¬ {len(MONITORED_USERS)} ä¸ªç”¨æˆ·")
        
        return tweets_data
        
    except Exception as e:
        print(f"Ã— æŠ“å–åˆ—è¡¨å¤±è´¥: {e}")
        return []

async def monitor_list_once(driver, list_url, pushed_ids):
    """ç›‘å¬åˆ—è¡¨ä¸€æ¬¡
    
    Args:
        driver: Selenium WebDriverå®ä¾‹
        list_url: æ¨ç‰¹åˆ—è¡¨URL
        pushed_ids: å·²æ¨é€çš„æ¨æ–‡IDé›†åˆ
        
    Returns:
        int: æ–°æ¨é€çš„æ¨æ–‡æ•°é‡
    """
    print(f"\n{'='*60}")
    print(f"å¼€å§‹ç›‘å¬åˆ—è¡¨: {list_url}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}")
    
    # æŠ“å–åˆ—è¡¨ä¸­çš„æ¨æ–‡
    tweets = scrape_list_tweets(driver, list_url, MAX_TWEETS_PER_CHECK)
    
    if not tweets:
        print("æœªè·å–åˆ°æ¨æ–‡")
        return 0
    
    # è¿‡æ»¤å‡ºæ–°æ¨æ–‡ï¼ˆæœªæ¨é€è¿‡çš„ï¼‰
    new_tweets = [t for t in tweets if t['id'] not in pushed_ids]
    
    if not new_tweets:
        print(f"æ²¡æœ‰æ–°æ¨æ–‡ï¼ˆå…±æ£€æŸ¥äº† {len(tweets)} æ¡æ¨æ–‡ï¼‰")
        return 0
    
    print(f"\nå‘ç° {len(new_tweets)} æ¡æ–°æ¨æ–‡ï¼Œå‡†å¤‡æ¨é€...")
    
    # æŒ‰æ—¶é—´æ’åºï¼ˆæ—§çš„åœ¨å‰ï¼Œæ–°çš„åœ¨åï¼‰
    # è¿™æ ·æ¨é€æ—¶å°±æ˜¯ä»æ—§åˆ°æ–°çš„é¡ºåº
    new_tweets.sort(key=lambda x: x['time'] if x['time'] else '')
    
    # æ¨é€æ–°æ¨æ–‡
    pushed_count = 0
    for idx, tweet in enumerate(new_tweets, 1):
        print(f"\n--- æ¨é€ç¬¬ {idx}/{len(new_tweets)} æ¡æ–°æ¨æ–‡ ---")
        print(f"ID: {tweet['id']}")
        print(f"ä½œè€…: {tweet['handle']}")
        print(f"æ—¶é—´: {tweet['time']}")
        
        # å‘é€åˆ°webhook
        success = await send_tweet_to_webhook(tweet)
        
        if success:
            # ä¿å­˜å·²æ¨é€ID
            save_pushed_id(tweet['id'])
            pushed_ids.add(tweet['id'])
            pushed_count += 1
        
        # æ¨æ–‡ä¹‹é—´é—´éš”
        if idx < len(new_tweets):
            await asyncio.sleep(2)
    
    print(f"\nâœ“ æœ¬æ¬¡æˆåŠŸæ¨é€ {pushed_count} æ¡æ–°æ¨æ–‡")
    return pushed_count

def check_login_status(driver):
    """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
    try:
        driver.get("https://x.com/home")
        time.sleep(3)
        
        current_url = driver.current_url
        if "login" in current_url or "i/flow/login" in current_url:
            print("\n" + "="*60)
            print("æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
            print("æµè§ˆå™¨å·²æ‰“å¼€ç™»å½•é¡µé¢ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­æ‰‹åŠ¨ç™»å½•ä½ çš„Xè´¦å·ã€‚")
            print("ç™»å½•æˆåŠŸåï¼Œå›åˆ°è¿™é‡Œï¼ŒæŒ‰Enteré”®ç»§ç»­æ‰§è¡Œç›‘å¬...")
            print("æ³¨æ„ï¼šç™»å½•ä¿¡æ¯å°†ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶æ— éœ€é‡å¤ç™»å½•")
            print("="*60)
            input()
            return True
        else:
            print("\nâœ“ æ£€æµ‹åˆ°å·²ç™»å½•çŠ¶æ€ï¼Œæ— éœ€é‡å¤ç™»å½•")
            return True
    except Exception as e:
        print(f"Ã— æ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥: {e}")
        return False

async def monitor_lists_loop():
    """ä¸»ç›‘å¬å¾ªç¯"""
    print("\n" + "="*60)
    print("æ¨ç‰¹åˆ—è¡¨ç›‘å¬è„šæœ¬")
    print("="*60)
    
    # åŠ è½½å·²æ¨é€çš„æ¨æ–‡ID
    pushed_ids = load_pushed_ids()
    print(f"å·²æ¨é€çš„æ¨æ–‡æ•°: {len(pushed_ids)}")
    
    # å¯åŠ¨æµè§ˆå™¨
    driver = None
    try:
        driver = create_undetected_driver()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        if not check_login_status(driver):
            print("Ã— ç™»å½•æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
        
        print(f"\nå¼€å§‹ç›‘å¬ {len(TWITTER_LISTS)} ä¸ªæ¨ç‰¹åˆ—è¡¨...")
        print(f"æ£€æŸ¥é—´éš”: {LIST_CHECK_INTERVAL} ç§’")
        print(f"æ¯æ¬¡æœ€å¤šè·å–: {MAX_TWEETS_PER_CHECK} æ¡æ¨æ–‡")
        print("\næç¤º: æŒ‰ Ctrl+C åœæ­¢ç›‘å¬\n")
        
        loop_count = 0
        
        while True:
            loop_count += 1
            print(f"\n{'#'*60}")
            print(f"ç¬¬ {loop_count} æ¬¡æ£€æŸ¥")
            print(f"{'#'*60}")
            
            total_new_tweets = 0
            
            # éå†æ‰€æœ‰åˆ—è¡¨
            for list_url in TWITTER_LISTS:
                try:
                    new_count = await monitor_list_once(driver, list_url, pushed_ids)
                    total_new_tweets += new_count
                    
                    # åˆ—è¡¨ä¹‹é—´çš„é—´éš”
                    if list_url != TWITTER_LISTS[-1]:
                        random_sleep(3, 6)
                        
                except Exception as e:
                    print(f"Ã— ç›‘å¬åˆ—è¡¨å‡ºé”™: {e}")
                    continue
            
            # æ‰“å°æœ¬è½®æ€»ç»“
            print(f"\n{'='*60}")
            print(f"ç¬¬ {loop_count} æ¬¡æ£€æŸ¥å®Œæˆ")
            print(f"æœ¬è½®å…±æ¨é€ {total_new_tweets} æ¡æ–°æ¨æ–‡")
            print(f"ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {LIST_CHECK_INTERVAL} ç§’å")
            print(f"{'='*60}")
            
            # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
            print(f"\nç­‰å¾… {LIST_CHECK_INTERVAL} ç§’...")
            time.sleep(LIST_CHECK_INTERVAL)
            
    except KeyboardInterrupt:
        print("\n\næ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        
    except Exception as e:
        print(f"\nÃ— ç›‘å¬è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if driver:
            print("\nå…³é—­æµè§ˆå™¨...")
            driver.quit()
        print("ç›‘å¬å·²åœæ­¢")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    # è¿è¡Œç›‘å¬å¾ªç¯
    asyncio.run(monitor_lists_loop())

