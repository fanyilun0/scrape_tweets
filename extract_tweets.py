import re
import time
import csv
import os
import requests
import random
import json
from datetime import datetime
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.common.action_chains import ActionChains

# ä½ æä¾›çš„åŒ…å«æ¨æ–‡é“¾æ¥çš„åŸå§‹æ–‡æœ¬
# original_text = """
# è¿™æ®µæ—¶é—´é‡æ–°ç¿»çœ‹äº†è‡ªå·±çš„æ¨æ–‡ï¼ŒæŠŠå…¶ä¸­æˆ‘è§‰å¾—æ¯”è¾ƒç²¾åçš„å†…å®¹å’Œä¸€äº›é«˜å…‰æ“ä½œæ•´ç†äº†å‡ºæ¥ï¼Œè™½ç„¶å¸‚åœºçŠ¶å†µä¸€ç›´åœ¨å˜åŒ–ï¼Œå…·ä½“çš„æ–¹æ³•æœªå¿…é€‚ç”¨äº†ï¼Œä½†æ˜¯å¦‚ä½•å¯»æ‰¾alphaã€æ€ä¹ˆå°†è®¤çŸ¥ä¸å®è·µç›¸ç»“åˆï¼Œè¿™äº›æ€ç»´ä¾ç„¶æ˜¯æœ‰å…±æ€§çš„ï¼Œå¸Œæœ›èƒ½å¯¹å¤§å®¶æœ‰æ‰€å¸®åŠ©ã€‚ ä»¥ä¸‹æŒ‰æ—¶é—´é¡ºåºåˆ—å‡ºï¼š 2022.04.22 NFTå›¾ç‹—MintæŒ‡å— 
# https://x.com/0xSunNFT/status/1517468623207424003
# â€¦2022.05.02 çŒ´åœ°é€ƒé¡¶è·åˆ©200ETH 
# https://x.com/0xSunNFT/status/1521151261193560065
# â€¦ 2022.07.21 NFTæŠ¢è´­BotæŒ‡å—
# https://x.com/0xSunNFT/status/1538916947647430656
# â€¦ 2022.09.21 DogeClubå•ä¸ªå›¾ç‹—è·åˆ©70ETH 
# https://x.com/0xSunNFT/status/1572257431178342400
# â€¦ 2023.04.19 MemecoinåŸºç¡€ç§‘æ™®ï¼ˆå½“æ—¶å¸‚åœºçƒ­ç‚¹æ­£ä»NFTè½¬ç§»åˆ°åœŸç‹—å¸ï¼‰ 
# https://x.com/0xSunNFT/status/1648673250845790209
# â€¦ 2023.05.09 é‡å¿ƒæ¢åˆ°åœŸç‹—å¸åå•å‘¨æµ®ç›ˆ100ETH 
# https://x.com/0xSunNFT/status/1655926338778464259
# â€¦ 2023.07.29 Paulyçš„Pondå¼€ç›˜3åˆ†é’Ÿ1ETHå˜æˆ44.5ETH
# https://x.com/0xSunNFT/status/1684957909887954944
# â€¦ 2023.09.12 é¦™è•‰æªBanana Gunå‘å¸å¤ç›˜ï¼Œç™½åå•+å¼€ç›˜é™è´­è·åˆ©50ETH
# https://x.com/0xSunNFT/status/1701321628859433004
# â€¦ 2024.01.05 èŠ‚ç‚¹çŒ´NodeMonkeså¤ç›˜ï¼Œå‚ä¸è·å…°æ‹ï¼Œ0.03BTCæˆæœ¬æœ€é«˜åœ°æ¿ä»·0.8BTCï¼Œè·åˆ©3BTC 
# https://x.com/0xSunNFT/status/1743160314982724012
# â€¦ 2024.01.29 ä»1ä¸‡~1000ä¸‡èµ„é‡‘é‡çº§ï¼Œå„ä¸ªé˜¶æ®µçš„æ€è€ƒä¸ç»å†
# https://x.com/0xSunNFT/status/1751888091487580633
# â€¦ 2024.02.26 é€šè¿‡é“¾ä¸Šäº¤æ˜“ä¸€ä¸ªæœˆèµš$1Mçš„å¤ç›˜ï¼ˆå‘å°„å°Mobyçš„é¢„å”®ã€Shibå®˜æ–¹çš„404é¡¹ç›®Shebã€DN404é¡¹ç›®ASTXã€å…¬å”®éšä¾¿æ‰“å¼€ç›˜ä¸Šå¸å®‰çš„Portalã€Merliné“¾çš„$Huhuç­‰ï¼‰
# https://x.com/0xSunNFT/status/1761953815765696648
# â€¦ 2024.06.19 åæ€è‡ªå·±åœ¨æ“…é•¿çš„é“¾ä¸Šèµ›é“è¿‡äºè°¨æ…ï¼Œåœ¨ä¸ç†Ÿçš„å±±å¯¨æ“ä½œä¸Šä»“ä½è¿‡é‡
# https://x.com/0xSunNFT/status/1803282305886330944
# â€¦ 2024.07.08 å„ç§åŸå› å¯¼è‡´ä¸€å¤©è¸ç©ºæ•°ä¸ªé‡‘ç‹—åçš„æ€è€ƒ 
# https://x.com/0xSunNFT/status/1799387231456833976
# â€¦2024.07.17 ç‰¹æœ—æ™®æªå‡»äº‹ä»¶ï¼Œç›¸å…³çƒ­ç‚¹åœŸç‹—$Fightè·åˆ©13ä¸‡uå¤ç›˜ 
# https://x.com/0xSunNFT/status/1813419967930667051
# â€¦ 2024.07.24 å…³äºâ€œèªæ˜é’±â€å’Œâ€œè·Ÿå•â€çš„çœ‹æ³• 
# https://x.com/0xSunNFT/status/1815968611384819977
# â€¦ 2024.07.31 éº»å‰å›¾å¸é¡¹ç›®â€œBAYCâ€å¼€ç›˜å‘ç°å¥—åˆ©æ–¹æ³•ï¼Œ1åˆ†é’Ÿæ”¶è·15ä¸‡u 
# https://x.com/0xSunNFT/status/1818666552461570284
# â€¦ 2024.08.23 Simon Caté¢„å”®å¤ç›˜ï¼Œä¸€æ¬¡å ªç§°å®Œç¾çš„æ‰“æ–°æœºä¼š
# https://x.com/0xSunNFT/status/1826924435930333294
# â€¦ 2024.10.11 2Må¸‚å€¼å¼€å§‹è½¬æ¨Goatç›¸å…³å†…å®¹ï¼Œè·åˆ©10ä¸‡u 
# https://x.com/0xSunNFT/status/1844761629705318449
# â€¦2024.11.03 é©¬æ–¯å…‹ç½®é¡¶æ¾é¼ ç¬¬ä¸€æ—¶é—´å‘æ¨ï¼Œè·åˆ©19ä¸‡u 
# https://x.com/0xSunNFT/status/1852831467119743143
# â€¦ 2024.11.11 å¤ç›˜SOLå•é“¾å•æœˆ1Mæ”¶ç›Š 
# https://x.com/0xSunNFT/status/1855882780334604736
# â€¦ 2024.11.16 DeSciç”Ÿæ€èµ·é£å‰æ¢³ç†çº¿ç´¢ï¼ŒRIF+UROè·åˆ©30ä¸‡u
# https://x.com/0xSunNFT/status/1857710057124728961
# â€¦ 2024.12.14 å¤ç›˜ä¸ºä»€ä¹ˆä¼šå–é£è‡ªå·±æ—©æœŸå‘æ˜çš„é¡¹ç›®ï¼Œåšå¤šGoatå’ŒPnutè·åˆ©$2M
# https://x.com/0xSunNFT/status/1867845182001229920
# â€¦ 2025.01.05 AIèµ›é“ç›¸å…³ä»£å¸ä¸€å‘¨è·åˆ©$1Må¤ç›˜ 
# https://x.com/0xSunNFT/status/1875720961775083896
# â€¦ 2025.01.18 ç‰¹æœ—æ™®æ¨ç‰¹å‘å¸ƒä»£å¸åˆçº¦åâ€œäººåªæ´»ä¸€æ¬¡â€ 
# https://x.com/0xSunNFT/status/1880446520627196118
# â€¦ 2025.01.19 $Trumpå•å¸æµ®ç›ˆ$20M+
# https://x.com/0xSunNFT/status/1880769711480389784
# â€¦ 2025.01.25 ç‰¹æœ—æ™®è€å©†å‘å¸$Melaniaï¼Œå¯¹åå¸‚çœ‹æ³•ç”±ä¹è§‚å˜ä¸ºä¸ç¡®å®š
# https://x.com/0xSunNFT/status/1882971617783173341
# â€¦ 2025.02.03 è®¤ä¸ºä¸å­˜åœ¨å…¨é¢æ™®æ¶¨ï¼Œå¼€å§‹ä½å€åšç©ºå±±å¯¨å¸ 
# https://x.com/0xSunNFT/status/1886229854385025198
# â€¦2025.03.30 å¯¹è‡ªå·±ä¸‰å¹´æ¥å¸åœˆç¬”è®°çš„æ•´ç†ä¸åˆ†äº« 
# https://x.com/0xSunNFT/status/1906249868798230597
# â€¦ 2025.04.07 åšç©ºå±±å¯¨å¸çš„é»„é‡‘æœŸå·²ç»è¿‡å» 
# https://x.com/0xSunNFT/status/1909151413822980357
# â€¦ 2025.04.19 ä¸è¦ç”¨æˆ˜æœ¯ä¸Šçš„å‹¤å¥‹æ©ç›–æˆ˜ç•¥ä¸Šçš„æ‡’æƒ° 
# https://x.com/0xSunNFT/status/1913608106275397829
# â€¦2025.05.01 $Gorkè·åˆ©18ä¸‡u 
# https://x.com/0xSunNFT/status/1917685646409490783
# â€¦ 2025.05.31 è®¤ä¸ºå¤§éƒ¨åˆ†å±±å¯¨å·²ç»é‡æ–°è¿›å…¥ä¸‹è·Œè¶‹åŠ¿
# https://x.com/0xSunNFT/status/1928769488146804791
# â€¦ 2025.07.08 PumpFunå…¬å”®æ˜¯æœºä¼š 
# https://x.com/0xSunNFT/status/1942314375051960807
# â€¦ 2025.07.23 é“¾ä¸ŠMemeä¸¤å¤§æ–¹æ³•è®ºï¼Œå™äº‹äº¤æ˜“å’Œåœ°å€æŒ–æ˜ 
# https://x.com/0xSunNFT/status/1948021791487824032
# â€¦ 2025.08.01 åšå¤šETHï¼Œåšç©ºå±±å¯¨å¸å¯¹å†²
# https://x.com/0xSunNFT/status/1951099879906058707
# â€¦ 2025.09.02 å¤ç›˜åšç©ºWLFIè·åˆ©$1M 
# https://x.com/0xSunNFT/status/1962792706905915473
# """


original_text ="""
https://x.com/TingHu888/status/1988123397319200795
https://x.com/TingHu888/status/1988082000264335693
https://x.com/TingHu888/status/1987856180694413457
https://x.com/TingHu888/status/1987786875747389833
https://x.com/TingHu888/status/1987757492596847048
https://x.com/TingHu888/status/1987376007154905519
https://x.com/TingHu888/status/1987004310497251728
https://x.com/TingHu888/status/1986999026252976425
https://x.com/TingHu888/status/1986996340493295989
https://x.com/TingHu888/status/1986814825654353951
https://x.com/TingHu888/status/1986808847504482612
https://x.com/TingHu888/status/1986807227496411265
https://x.com/TingHu888/status/1986364658786443528
https://x.com/TingHu888/status/1986303935968387147
https://x.com/TingHu888/status/1986297924125663562
https://x.com/TingHu888/status/1986277122105876730
https://x.com/TingHu888/status/1986090834199273935
https://x.com/TingHu888/status/1986081605040124179
https://x.com/TingHu888/status/1986077001397223472
https://x.com/TingHu888/status/1986074709658910992
https://x.com/TingHu888/status/1986010071491543158
https://x.com/TingHu888/status/1986008321963573361
https://x.com/TingHu888/status/1986002985898680756
https://x.com/TingHu888/status/1985370005425553747
https://x.com/TingHu888/status/1983841722766647783
https://x.com/TingHu888/status/1980263750117859773
https://x.com/TingHu888/status/1977618151929205162
https://x.com/TingHu888/status/1977445851296669926
https://x.com/TingHu888/status/1972912363428012431
https://x.com/TingHu888/status/1960788158368412007
https://x.com/TingHu888/status/1960168872407163279
https://x.com/TingHu888/status/1955650244760461802
https://x.com/TingHu888/status/1917058963339940004
https://x.com/TingHu888/status/1892878860519145875
https://x.com/TingHu888/status/1880121476453646473
https://x.com/TingHu888/status/1878824888276054275
https://x.com/TingHu888/status/1872202526835229136
https://x.com/TingHu888/status/1870791121024282858
https://x.com/TingHu888/status/1866894859245850722
https://x.com/TingHu888/status/1865453960854982843
https://x.com/TingHu888/status/1864258526627156448
https://x.com/TingHu888/status/1862061149090681302
https://x.com/TingHu888/status/1859823309418021014
https://x.com/TingHu888/status/1785329783146258454
https://x.com/TingHu888/status/1745348180483699022
https://x.com/TingHu888/status/1599699347033456640
https://x.com/TingHu888/status/1557618125612339201
https://x.com/TingHu888/status/1536342879039172609
https://x.com/TingHu888/status/1529484387221651457
https://x.com/TingHu888/status/1527639728585326592
https://x.com/TingHu888/status/1525037842485116928
https://x.com/TingHu888/status/1524023604002050054
https://x.com/TingHu888/status/1523705712140255232
https://x.com/TingHu888/status/1522614203982696448
https://x.com/TingHu888/status/1522483527178387456
https://x.com/TingHu888/status/1520655908916785152
https://x.com/TingHu888/status/1520409694883676160
https://x.com/TingHu888/status/1518628879794991104
https://x.com/TingHu888/status/1516830342015258626
https://x.com/TingHu888/status/1515979885046509572
https://x.com/TingHu888/status/1515620527670398978
https://x.com/TingHu888/status/1514496947507572737
https://x.com/TingHu888/status/1513043200830676994
https://x.com/TingHu888/status/1510879716290744325
https://x.com/TingHu888/status/1510507737394073600
https://x.com/TingHu888/status/1510136534066155520
https://x.com/TingHu888/status/1504514378548523008
https://x.com/TingHu888/status/1502968630262534144
https://x.com/TingHu888/status/1497467639924674563
https://x.com/TingHu888/status/1495406320929112064
https://x.com/TingHu888/status/1495307872779247616
https://x.com/TingHu888/status/1491720862319648771
https://x.com/TingHu888/status/1488772594715475969
"""

# ==================== é…ç½®åŒºåŸŸ ====================
# ä»£ç†é…ç½®ï¼ˆå¦‚æœä¸éœ€è¦ä»£ç†ï¼Œè®¾ç½®ä¸ºNoneï¼‰
PROXY = "http://127.0.0.1:7890"  # é»˜è®¤ä»£ç†åœ°å€ï¼Œå¯ä»¥è®¾ç½®ä¸ºNoneç¦ç”¨

# æ˜¯å¦ä½¿ç”¨æŒä¹…åŒ–Profileï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œéœ€è¦æ‰‹åŠ¨ç™»å½•ï¼Œä¹‹åä¼šä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
USE_PERSISTENT_PROFILE = True
PROFILE_DIR = "./chrome_profile"

# å·²æŠ“å–æ¨æ–‡IDè®°å½•æ–‡ä»¶ï¼ˆé¿å…é‡å¤æŠ“å–ï¼‰
SCRAPED_IDS_FILE = "scraped_tweet_ids.json"

# æŠ“å–é…ç½®
MAX_RETRIES = 3  # æ¯æ¡æ¨æ–‡æœ€å¤§é‡è¯•æ¬¡æ•°
REQUEST_DELAY_MIN = 5  # è¯·æ±‚é—´éš”æœ€å°ç§’æ•°
REQUEST_DELAY_MAX = 10  # è¯·æ±‚é—´éš”æœ€å¤§ç§’æ•°
TIMEOUT_SECONDS = 30  # é¡µé¢åŠ è½½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# ==================== è¾…åŠ©å‡½æ•° ====================
def load_scraped_ids():
    """åŠ è½½å·²æŠ“å–çš„æ¨æ–‡ID"""
    if os.path.exists(SCRAPED_IDS_FILE):
        try:
            with open(SCRAPED_IDS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_scraped_id(tweet_id):
    """ä¿å­˜å·²æŠ“å–çš„æ¨æ–‡ID"""
    scraped_ids = load_scraped_ids()
    scraped_ids.add(tweet_id)
    with open(SCRAPED_IDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(scraped_ids), f, indent=2)

def random_sleep(min_sec=1, max_sec=3):
    """éšæœºå»¶æ—¶ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
    sleep_time = random.uniform(min_sec, max_sec)
    print(f"  éšæœºç­‰å¾… {sleep_time:.2f} ç§’...")
    time.sleep(sleep_time)

def simulate_human_scroll(driver):
    """æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º"""
    print("  æ¨¡æ‹Ÿé¡µé¢æ»šåŠ¨...")
    scroll_times = random.randint(1, 3)
    for _ in range(scroll_times):
        scroll_amount = random.randint(200, 500)
        driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        time.sleep(random.uniform(0.5, 1.5))

def create_undetected_driver():
    """åˆ›å»ºåæ£€æµ‹çš„Chromeæµè§ˆå™¨å®ä¾‹"""
    print("æ­£åœ¨å¯åŠ¨ undetected_chromedriver...")
    
    options = uc.ChromeOptions()
    
    # æ·»åŠ ä»£ç†é…ç½®
    if PROXY:
        print(f"  é…ç½®ä»£ç†: {PROXY}")
        options.add_argument(f'--proxy-server={PROXY}')
    
    # ä½¿ç”¨æŒä¹…åŒ–Profile
    if USE_PERSISTENT_PROFILE:
        print(f"  ä½¿ç”¨æŒä¹…åŒ–Profile: {PROFILE_DIR}")
        options.add_argument(f'--user-data-dir={PROFILE_DIR}')
    
    # å…¶ä»–ä¼˜åŒ–é€‰é¡¹
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    
    try:
        driver = uc.Chrome(options=options)
        print("âœ“ undetected_chromedriver å¯åŠ¨æˆåŠŸ")
        return driver
    except Exception as e:
        print(f"Ã— å¯åŠ¨å¤±è´¥: {e}")
        print("\nè¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆ:")
        print("1. å®‰è£…undetected-chromedriver: pip install undetected-chromedriver")
        print("2. ç¡®ä¿Chromeæµè§ˆå™¨å·²å®‰è£…")
        print("3. å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£å¸¸è¿è¡Œ")
        raise

# ==================== ä¸»ç¨‹åº ====================

# 1. ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æ¨æ–‡URL
tweet_urls = re.findall(r'https://x\.com/\w+/status/\d+', original_text)
print(f"æ£€æµ‹åˆ° {len(tweet_urls)} æ¡æ¨æ–‡é“¾æ¥ã€‚")

# åŠ è½½å·²æŠ“å–çš„æ¨æ–‡ID
scraped_ids = load_scraped_ids()
print(f"å·²æŠ“å–çš„æ¨æ–‡æ•°: {len(scraped_ids)}")

# 2. åˆå§‹åŒ–Selenium WebDriver
print("\næ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
driver = create_undetected_driver()

try:
    # 3. æ£€æŸ¥ç™»å½•çŠ¶æ€
    driver.get("https://x.com/home")
    time.sleep(3)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
    current_url = driver.current_url
    if "login" in current_url or "i/flow/login" in current_url:
        print("\n" + "="*50)
        print("æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
        print("æµè§ˆå™¨å·²æ‰“å¼€ç™»å½•é¡µé¢ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­æ‰‹åŠ¨ç™»å½•ä½ çš„Xè´¦å·ã€‚")
        print("ç™»å½•æˆåŠŸåï¼Œå›åˆ°è¿™é‡Œï¼ŒæŒ‰Enteré”®ç»§ç»­æ‰§è¡ŒæŠ“å–...")
        print("æ³¨æ„ï¼šç™»å½•ä¿¡æ¯å°†ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶æ— éœ€é‡å¤ç™»å½•")
        print("="*50)
        input() # ç­‰å¾…ç”¨æˆ·æŒ‰Enteré”®
    else:
        print("\nâœ“ æ£€æµ‹åˆ°å·²ç™»å½•çŠ¶æ€ï¼Œæ— éœ€é‡å¤ç™»å½•")
        print("æç¤ºï¼šå¦‚éœ€åˆ‡æ¢è´¦å·ï¼Œè¯·åˆ é™¤ chrome_profile ç›®å½•åé‡æ–°è¿è¡Œ")

    print("\nå¼€å§‹æŠ“å–æ¨æ–‡å†…å®¹...\n")
    
    # 4. åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•å’Œè¾“å‡ºæ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    images_dir = f"tweets_images_{timestamp}"
    os.makedirs(images_dir, exist_ok=True)
    
    csv_filename = f"tweets_data_{timestamp}.csv"
    md_filename = f"tweets_data_{timestamp}.md"
    
    # åˆå§‹åŒ–CSVæ–‡ä»¶ï¼ˆå†™å…¥è¡¨å¤´ï¼‰
    csv_file = open(csv_filename, 'w', newline='', encoding='utf-8-sig')
    fieldnames = ['åºå·', 'ç”¨æˆ·å', 'å‘å¸ƒæ—¶é—´', 'æ¨æ–‡é“¾æ¥', 'æ¨æ–‡å†…å®¹', 'å›¾ç‰‡æ•°é‡', 'å›¾ç‰‡URL']
    csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
    csv_writer.writeheader()
    csv_file.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜
    print(f"âœ“ å·²åˆ›å»ºCSVæ–‡ä»¶: {csv_filename}")
    
    # åˆå§‹åŒ–Markdownæ–‡ä»¶ï¼ˆå†™å…¥å¤´éƒ¨ä¿¡æ¯ï¼‰
    md_file = open(md_filename, 'w', encoding='utf-8')
    md_file.write(f"# æ¨æ–‡åˆé›†\n\n")
    md_file.write(f"**æŠ“å–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    md_file.write(f"**æ¨æ–‡æ€»æ•°**: å¾…ç»Ÿè®¡...\n\n")
    md_file.write("---\n\n")
    md_file.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜
    print(f"âœ“ å·²åˆ›å»ºMarkdownæ–‡ä»¶: {md_filename}\n")
    
    # è®¡æ•°å™¨
    success_count = 0
    total_images_count = 0
    
    # 5. å¾ªç¯è®¿é—®æ¯ä¸ªURLå¹¶æŠ“å–å†…å®¹
    for i, url in enumerate(tweet_urls):
        # æå–æ¨æ–‡ID
        tweet_id = url.split('/')[-1]
        
        # æ£€æŸ¥æ˜¯å¦å·²æŠ“å–
        if tweet_id in scraped_ids:
            print(f"--- è·³è¿‡ç¬¬ {i+1}/{len(tweet_urls)} æ¡ï¼ˆå·²æŠ“å–ï¼‰: {url} ---")
            continue
            
        print(f"--- æ­£åœ¨æŠ“å–ç¬¬ {i+1}/{len(tweet_urls)} æ¡: {url} ---")
        
        # é‡è¯•æœºåˆ¶
        retry_count = 0
        success = False
        
        while retry_count < MAX_RETRIES and not success:
            try:
                if retry_count > 0:
                    print(f"  ç¬¬ {retry_count + 1} æ¬¡å°è¯•...")
                    # é‡è¯•å‰ç­‰å¾…æ›´é•¿æ—¶é—´ï¼ˆé€æ¬¡å¢åŠ ç­‰å¾…æ—¶é—´ï¼‰
                    wait_time = random.uniform(10, 20) * (retry_count + 1)
                    print(f"  ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                
                driver.get(url)
                
                # å¢åŠ åˆå§‹ç­‰å¾…æ—¶é—´ï¼Œè®©é¡µé¢å®Œå…¨åŠ è½½
                time.sleep(random.uniform(2, 4))
                
                # æ£€æŸ¥æ˜¯å¦è¢«é™æµï¼ˆæŸ¥çœ‹é¡µé¢æ ‡é¢˜ï¼‰
                try:
                    page_title = driver.title.lower()
                    if 'rate limit' in page_title or 'error' in page_title:
                        print(f"  âš ï¸ æ£€æµ‹åˆ°é™æµé¡µé¢ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´...")
                        time.sleep(random.uniform(30, 60))
                        raise TimeoutException("Rate limited")
                except:
                    pass
                
                # ç­‰å¾…æ¨æ–‡å†…å®¹åŠ è½½å‡ºæ¥
                wait = WebDriverWait(driver, TIMEOUT_SECONDS)
                tweet_article = wait.until(
                    EC.presence_of_element_located((By.XPATH, "//article[@data-testid='tweet']"))
                )
                
                success = True  # æˆåŠŸåŠ è½½
                
            except TimeoutException:
                retry_count += 1
                if retry_count >= MAX_RETRIES:
                    print(f"  Ã— è¶…æ—¶ï¼šé¡µé¢åŠ è½½å¤±è´¥ï¼Œå·²å°è¯• {MAX_RETRIES} æ¬¡")
                    break
                else:
                    print(f"  âš ï¸ è¶…æ—¶ï¼Œå‡†å¤‡é‡è¯• ({retry_count}/{MAX_RETRIES})")
                    continue
            except Exception as e:
                retry_count += 1
                if retry_count >= MAX_RETRIES:
                    print(f"  Ã— é”™è¯¯ï¼š{str(e)[:100]}")
                    break
                else:
                    print(f"  âš ï¸ å‡ºç°é”™è¯¯ï¼Œå‡†å¤‡é‡è¯• ({retry_count}/{MAX_RETRIES})")
                    continue
        
        if not success:
            print(f"æŠ“å–å¤±è´¥: {url}\nå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°\n")
            # å¤±è´¥åç­‰å¾…æ›´é•¿æ—¶é—´ï¼Œé¿å…è§¦å‘æ›´ä¸¥æ ¼çš„é™æµ
            time.sleep(random.uniform(20, 30))
            continue
        
        try:
            
            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º
            simulate_human_scroll(driver)
            
            # æå–æ¨æ–‡æ­£æ–‡
            try:
                tweet_text_element = tweet_article.find_element(By.XPATH, ".//div[@data-testid='tweetText']")
                tweet_text = tweet_text_element.text
            except NoSuchElementException:
                tweet_text = ""
            
            # æå–ç”¨æˆ·åï¼ˆ@handleï¼‰
            try:
                user_handle_element = tweet_article.find_element(By.XPATH, ".//div[@data-testid='User-Name']//a[contains(@href, '/')]")
                user_handle = user_handle_element.get_attribute('href').split('/')[-1]
                user_handle = f"@{user_handle}"
            except NoSuchElementException:
                user_handle = ""
            
            # æå–æ¨æ–‡æ—¶é—´
            tweet_time = ""
            try:
                time_element = tweet_article.find_element(By.XPATH, ".//time")
                tweet_time = time_element.get_attribute('datetime')
                # æ ¼å¼åŒ–æ—¶é—´ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                if tweet_time:
                    dt = datetime.fromisoformat(tweet_time.replace('Z', '+00:00'))
                    tweet_time = dt.strftime('%Y-%m-%d %H:%M:%S')
            except NoSuchElementException:
                pass
            

            # æå–å›¾ç‰‡ï¼ˆæ–°æ–¹æ³•ï¼šç›´æ¥ä»ç¼©ç•¥å›¾URLæ¨å¯¼åŸå›¾ï¼‰
            image_urls = []
            try:
                # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«å›¾ç‰‡çš„ div å…ƒç´ 
                photo_divs = tweet_article.find_elements(By.XPATH, ".//div[@data-testid='tweetPhoto']")
                
                # éå†æ¯ä¸ªå›¾ç‰‡å…ƒç´ ï¼Œæå–å…¶ src
                for photo_div in photo_divs:
                    # åœ¨æ¯ä¸ª div ä¸­æ‰¾åˆ° img æ ‡ç­¾
                    img_elements = photo_div.find_elements(By.TAG_NAME, "img")
                    for img_element in img_elements:
                        img_url = img_element.get_attribute('src')
                        
                        if img_url:
                            # å°†URLå‚æ•°æ›¿æ¢ä¸º 'name=orig' æ¥è·å–æœ€é«˜æ¸…çš„åŸå›¾
                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç¡®ä¿æ›¿æ¢çš„å‡†ç¡®æ€§
                            if 'name=' in img_url:
                                orig_img_url = re.sub(r'name=\w+', 'name=orig', img_url)
                            else:
                                # å¦‚æœURLä¸­æ²¡æœ‰ name å‚æ•°ï¼Œå¯èƒ½éœ€è¦æ·»åŠ  format=...&name=orig
                                # ä½†é€šå¸¸ç›´æ¥åœ¨æœ«å°¾æ·»åŠ  ?name=orig ä¹Ÿèƒ½å¥æ•ˆ
                                orig_img_url = img_url.split('?')[0] + '?format=jpg&name=orig'
                            
                            if orig_img_url not in image_urls:
                                image_urls.append(orig_img_url)
                                
                                # ä¸‹è½½å›¾ç‰‡
                                try:
                                    # ä»URLä¸­æå–æ–‡ä»¶åå’Œæ‰©å±•å
                                    file_name_part = orig_img_url.split('/')[-1].split('?')[0]
                                    ext_match = re.search(r'format=(\w+)', orig_img_url)
                                    ext = ext_match.group(1) if ext_match else 'jpg'
                                    
                                    img_filename = f"{file_name_part}.{ext}"
                                    img_path = os.path.join(images_dir, img_filename)

                                    # ä½¿ç”¨å¸¦æœ‰ User-Agent çš„ requests session æ¥ä¸‹è½½
                                    session = requests.Session()
                                    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
                                    img_response = session.get(orig_img_url, headers=headers, timeout=15)
                                    
                                    if img_response.status_code == 200:
                                        with open(img_path, 'wb') as f:
                                            f.write(img_response.content)
                                        print(f"  âœ“ å·²ä¿å­˜å›¾ç‰‡: {img_filename}")
                                    else:
                                        print(f"  Ã— ä¸‹è½½å›¾ç‰‡å¤±è´¥ (çŠ¶æ€ç : {img_response.status_code})")
                                except Exception as download_error:
                                    print(f"  Ã— ä¸‹è½½å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {download_error}")

            except NoSuchElementException:
                pass  # è¯¥æ¨æ–‡æ²¡æœ‰å›¾ç‰‡

            
            print(f"ç”¨æˆ·å: {user_handle}")
            print(f"å‘å¸ƒæ—¶é—´: {tweet_time}")
            print(f"å†…å®¹:\n{tweet_text}")
            print(f"å›¾ç‰‡æ•°é‡: {len(image_urls)}\n")
            
            # ç«‹å³å†™å…¥CSVæ–‡ä»¶
            success_count += 1
            total_images_count += len(image_urls)
            images_str = '; '.join(image_urls) if image_urls else ''
            
            csv_writer.writerow({
                'åºå·': success_count,
                'ç”¨æˆ·å': user_handle,
                'å‘å¸ƒæ—¶é—´': tweet_time,
                'æ¨æ–‡é“¾æ¥': url,
                'æ¨æ–‡å†…å®¹': tweet_text,
                'å›¾ç‰‡æ•°é‡': len(image_urls),
                'å›¾ç‰‡URL': images_str
            })
            csv_file.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜
            
            # ç«‹å³å†™å…¥Markdownæ–‡ä»¶
            md_file.write(f"## {success_count}. æ¨æ–‡ - {user_handle}\n\n")
            md_file.write(f"**å‘å¸ƒæ—¶é—´**: {tweet_time}\n\n")
            md_file.write(f"**æ¨æ–‡é“¾æ¥**: [{url}]({url})\n\n")
            
            # æ¨æ–‡å†…å®¹
            if tweet_text:
                md_file.write(f"**å†…å®¹**:\n\n")
                content_lines = tweet_text.split('\n')
                for line in content_lines:
                    if line.strip():
                        md_file.write(f"{line}\n\n")
                    else:
                        md_file.write("\n")
            
            # å›¾ç‰‡
            if image_urls:
                md_file.write(f"**å›¾ç‰‡** ({len(image_urls)} å¼ ):\n\n")
                for img_idx, img_url in enumerate(image_urls, 1):
                    # æœ¬åœ°å›¾ç‰‡è·¯å¾„
                    local_img = f"{images_dir}/tweet_{success_count}_img_{img_idx}.jpg"
                    if os.path.exists(local_img):
                        md_file.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    elif os.path.exists(local_img.replace('.jpg', '.png')):
                        local_img = local_img.replace('.jpg', '.png')
                        md_file.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    elif os.path.exists(local_img.replace('.jpg', '.gif')):
                        local_img = local_img.replace('.jpg', '.gif')
                        md_file.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    
                    # åŒæ—¶ä¿ç•™åŸå§‹URLé“¾æ¥
                    md_file.write(f"*åŸå›¾é“¾æ¥*: [{img_url}]({img_url})\n\n")
                    md_file.write(f"![image]({img_url})\n\n")
            
            md_file.write("---\n\n")
            md_file.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜
            
            print(f"âœ“ å·²å†™å…¥åˆ°æ–‡ä»¶ (åºå·: {success_count})\n")
            
            # ä¿å­˜å·²æŠ“å–çš„æ¨æ–‡ID
            save_scraped_id(tweet_id)
            
            # éšæœºæ‰§è¡Œä¸€äº›"æ„å¤–"æ“ä½œï¼ˆ5%æ¦‚ç‡ï¼‰
            if random.random() < 0.05:
                action = random.choice(['refresh', 'scroll_top', 'mouse_move'])
                if action == 'refresh':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] åˆ·æ–°é¡µé¢...")
                    driver.refresh()
                    time.sleep(random.uniform(2, 4))
                elif action == 'scroll_top':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨...")
                    driver.execute_script("window.scrollTo(0, 0);")
                    time.sleep(random.uniform(1, 2))
                elif action == 'mouse_move':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] éšæœºç§»åŠ¨é¼ æ ‡...")
                    try:
                        actions = ActionChains(driver)
                        actions.move_by_offset(random.randint(50, 200), random.randint(50, 200))
                        actions.perform()
                    except:
                        pass

            # éšæœºå»¶æ—¶ï¼Œæ¨¡ä»¿äººç±»è¡Œä¸ºï¼Œé™ä½è¢«å°é”çš„é£é™©
            random_sleep(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX)

        except Exception as e:
            print(f"æ•°æ®æå–å¤±è´¥: {url}\né”™è¯¯ä¿¡æ¯: {e}\n")
            # å³ä½¿å¤±è´¥ä¹Ÿéšæœºç­‰å¾…ä¸€ä¸‹
            time.sleep(random.uniform(5, 10))
            continue

finally:
    # å…³é—­æ–‡ä»¶
    try:
        csv_file.close()
        md_file.close()
        print(f"\nâœ“ æ–‡ä»¶å·²å…³é—­å¹¶ä¿å­˜")
    except:
        pass
    
    # å…³é—­æµè§ˆå™¨
    print("æ‰€æœ‰æŠ“å–ä»»åŠ¡å®Œæˆï¼Œå…³é—­æµè§ˆå™¨ã€‚")
    driver.quit()

# 6. æ›´æ–°Markdownæ–‡ä»¶çš„æ¨æ–‡æ€»æ•°å¹¶è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
try:
    # é‡æ–°æ‰“å¼€Markdownæ–‡ä»¶ï¼Œæ›´æ–°æ¨æ–‡æ€»æ•°
    with open(md_filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ›¿æ¢"å¾…ç»Ÿè®¡..."ä¸ºå®é™…æ•°é‡
    content = content.replace('**æ¨æ–‡æ€»æ•°**: å¾…ç»Ÿè®¡...', f'**æ¨æ–‡æ€»æ•°**: {success_count} æ¡')
    
    with open(md_filename, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
    print(f"  - CSVæ–‡ä»¶: {csv_filename}")
    print(f"  - Markdownæ–‡æ¡£: {md_filename}")
    print(f"  - å›¾ç‰‡ç›®å½•: {images_dir}/")
    print(f"  - æ¨æ–‡æ€»æ•°: {success_count}")
    print(f"  - å›¾ç‰‡æ€»æ•°: {total_images_count}")
    
    if success_count == 0:
        print("\nâš ï¸ æœªæˆåŠŸæŠ“å–åˆ°ä»»ä½•æ¨æ–‡æ•°æ®")
    else:
        print(f"\nâœ“ æ‰€æœ‰æ•°æ®å·²å®æ—¶ä¿å­˜ï¼Œå³ä½¿ä¸­é€”ä¸­æ–­ä¹Ÿä¸ä¼šä¸¢å¤±å·²æŠ“å–çš„æ•°æ®")
        
except Exception as e:
    print(f"\nâš ï¸ æ›´æ–°ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    print(f"ä½†å·²æŠ“å–çš„ {success_count} æ¡æ¨æ–‡æ•°æ®å·²å®‰å…¨ä¿å­˜")