import re
import time
import csv
import os
import requests
import random
import json
from datetime import datetime
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.common.action_chains import ActionChains

# ä½ æä¾›çš„åŒ…å«æ¨æ–‡é“¾æ¥çš„åŸå§‹æ–‡æœ¬
original_text = """
è¿™æ®µæ—¶é—´é‡æ–°ç¿»çœ‹äº†è‡ªå·±çš„æ¨æ–‡ï¼ŒæŠŠå…¶ä¸­æˆ‘è§‰å¾—æ¯”è¾ƒç²¾åçš„å†…å®¹å’Œä¸€äº›é«˜å…‰æ“ä½œæ•´ç†äº†å‡ºæ¥ï¼Œè™½ç„¶å¸‚åœºçŠ¶å†µä¸€ç›´åœ¨å˜åŒ–ï¼Œå…·ä½“çš„æ–¹æ³•æœªå¿…é€‚ç”¨äº†ï¼Œä½†æ˜¯å¦‚ä½•å¯»æ‰¾alphaã€æ€ä¹ˆå°†è®¤çŸ¥ä¸å®è·µç›¸ç»“åˆï¼Œè¿™äº›æ€ç»´ä¾ç„¶æ˜¯æœ‰å…±æ€§çš„ï¼Œå¸Œæœ›èƒ½å¯¹å¤§å®¶æœ‰æ‰€å¸®åŠ©ã€‚ ä»¥ä¸‹æŒ‰æ—¶é—´é¡ºåºåˆ—å‡ºï¼š 2022.04.22 NFTå›¾ç‹—MintæŒ‡å— 
https://x.com/0xSunNFT/status/1517468623207424003
â€¦2022.05.02 çŒ´åœ°é€ƒé¡¶è·åˆ©200ETH 
https://x.com/0xSunNFT/status/1521151261193560065
â€¦ 2022.07.21 NFTæŠ¢è´­BotæŒ‡å—
https://x.com/0xSunNFT/status/1538916947647430656
â€¦ 2022.09.21 DogeClubå•ä¸ªå›¾ç‹—è·åˆ©70ETH 
https://x.com/0xSunNFT/status/1572257431178342400
â€¦ 2023.04.19 MemecoinåŸºç¡€ç§‘æ™®ï¼ˆå½“æ—¶å¸‚åœºçƒ­ç‚¹æ­£ä»NFTè½¬ç§»åˆ°åœŸç‹—å¸ï¼‰ 
https://x.com/0xSunNFT/status/1648673250845790209
â€¦ 2023.05.09 é‡å¿ƒæ¢åˆ°åœŸç‹—å¸åå•å‘¨æµ®ç›ˆ100ETH 
https://x.com/0xSunNFT/status/1655926338778464259
â€¦ 2023.07.29 Paulyçš„Pondå¼€ç›˜3åˆ†é’Ÿ1ETHå˜æˆ44.5ETH
https://x.com/0xSunNFT/status/1684957909887954944
â€¦ 2023.09.12 é¦™è•‰æªBanana Gunå‘å¸å¤ç›˜ï¼Œç™½åå•+å¼€ç›˜é™è´­è·åˆ©50ETH
https://x.com/0xSunNFT/status/1701321628859433004
â€¦ 2024.01.05 èŠ‚ç‚¹çŒ´NodeMonkeså¤ç›˜ï¼Œå‚ä¸è·å…°æ‹ï¼Œ0.03BTCæˆæœ¬æœ€é«˜åœ°æ¿ä»·0.8BTCï¼Œè·åˆ©3BTC 
https://x.com/0xSunNFT/status/1743160314982724012
â€¦ 2024.01.29 ä»1ä¸‡~1000ä¸‡èµ„é‡‘é‡çº§ï¼Œå„ä¸ªé˜¶æ®µçš„æ€è€ƒä¸ç»å†
https://x.com/0xSunNFT/status/1751888091487580633
â€¦ 2024.02.26 é€šè¿‡é“¾ä¸Šäº¤æ˜“ä¸€ä¸ªæœˆèµš$1Mçš„å¤ç›˜ï¼ˆå‘å°„å°Mobyçš„é¢„å”®ã€Shibå®˜æ–¹çš„404é¡¹ç›®Shebã€DN404é¡¹ç›®ASTXã€å…¬å”®éšä¾¿æ‰“å¼€ç›˜ä¸Šå¸å®‰çš„Portalã€Merliné“¾çš„$Huhuç­‰ï¼‰
https://x.com/0xSunNFT/status/1761953815765696648
â€¦ 2024.06.19 åæ€è‡ªå·±åœ¨æ“…é•¿çš„é“¾ä¸Šèµ›é“è¿‡äºè°¨æ…ï¼Œåœ¨ä¸ç†Ÿçš„å±±å¯¨æ“ä½œä¸Šä»“ä½è¿‡é‡
https://x.com/0xSunNFT/status/1803282305886330944
â€¦ 2024.07.08 å„ç§åŸå› å¯¼è‡´ä¸€å¤©è¸ç©ºæ•°ä¸ªé‡‘ç‹—åçš„æ€è€ƒ 
https://x.com/0xSunNFT/status/1799387231456833976
â€¦2024.07.17 ç‰¹æœ—æ™®æªå‡»äº‹ä»¶ï¼Œç›¸å…³çƒ­ç‚¹åœŸç‹—$Fightè·åˆ©13ä¸‡uå¤ç›˜ 
https://x.com/0xSunNFT/status/1813419967930667051
â€¦ 2024.07.24 å…³äºâ€œèªæ˜é’±â€å’Œâ€œè·Ÿå•â€çš„çœ‹æ³• 
https://x.com/0xSunNFT/status/1815968611384819977
â€¦ 2024.07.31 éº»å‰å›¾å¸é¡¹ç›®â€œBAYCâ€å¼€ç›˜å‘ç°å¥—åˆ©æ–¹æ³•ï¼Œ1åˆ†é’Ÿæ”¶è·15ä¸‡u 
https://x.com/0xSunNFT/status/1818666552461570284
â€¦ 2024.08.23 Simon Caté¢„å”®å¤ç›˜ï¼Œä¸€æ¬¡å ªç§°å®Œç¾çš„æ‰“æ–°æœºä¼š
https://x.com/0xSunNFT/status/1826924435930333294
â€¦ 2024.10.11 2Må¸‚å€¼å¼€å§‹è½¬æ¨Goatç›¸å…³å†…å®¹ï¼Œè·åˆ©10ä¸‡u 
https://x.com/0xSunNFT/status/1844761629705318449
â€¦2024.11.03 é©¬æ–¯å…‹ç½®é¡¶æ¾é¼ ç¬¬ä¸€æ—¶é—´å‘æ¨ï¼Œè·åˆ©19ä¸‡u 
https://x.com/0xSunNFT/status/1852831467119743143
â€¦ 2024.11.11 å¤ç›˜SOLå•é“¾å•æœˆ1Mæ”¶ç›Š 
https://x.com/0xSunNFT/status/1855882780334604736
â€¦ 2024.11.16 DeSciç”Ÿæ€èµ·é£å‰æ¢³ç†çº¿ç´¢ï¼ŒRIF+UROè·åˆ©30ä¸‡u
https://x.com/0xSunNFT/status/1857710057124728961
â€¦ 2024.12.14 å¤ç›˜ä¸ºä»€ä¹ˆä¼šå–é£è‡ªå·±æ—©æœŸå‘æ˜çš„é¡¹ç›®ï¼Œåšå¤šGoatå’ŒPnutè·åˆ©$2M
https://x.com/0xSunNFT/status/1867845182001229920
â€¦ 2025.01.05 AIèµ›é“ç›¸å…³ä»£å¸ä¸€å‘¨è·åˆ©$1Må¤ç›˜ 
https://x.com/0xSunNFT/status/1875720961775083896
â€¦ 2025.01.18 ç‰¹æœ—æ™®æ¨ç‰¹å‘å¸ƒä»£å¸åˆçº¦åâ€œäººåªæ´»ä¸€æ¬¡â€ 
https://x.com/0xSunNFT/status/1880446520627196118
â€¦ 2025.01.19 $Trumpå•å¸æµ®ç›ˆ$20M+
https://x.com/0xSunNFT/status/1880769711480389784
â€¦ 2025.01.25 ç‰¹æœ—æ™®è€å©†å‘å¸$Melaniaï¼Œå¯¹åå¸‚çœ‹æ³•ç”±ä¹è§‚å˜ä¸ºä¸ç¡®å®š
https://x.com/0xSunNFT/status/1882971617783173341
â€¦ 2025.02.03 è®¤ä¸ºä¸å­˜åœ¨å…¨é¢æ™®æ¶¨ï¼Œå¼€å§‹ä½å€åšç©ºå±±å¯¨å¸ 
https://x.com/0xSunNFT/status/1886229854385025198
â€¦2025.03.30 å¯¹è‡ªå·±ä¸‰å¹´æ¥å¸åœˆç¬”è®°çš„æ•´ç†ä¸åˆ†äº« 
https://x.com/0xSunNFT/status/1906249868798230597
â€¦ 2025.04.07 åšç©ºå±±å¯¨å¸çš„é»„é‡‘æœŸå·²ç»è¿‡å» 
https://x.com/0xSunNFT/status/1909151413822980357
â€¦ 2025.04.19 ä¸è¦ç”¨æˆ˜æœ¯ä¸Šçš„å‹¤å¥‹æ©ç›–æˆ˜ç•¥ä¸Šçš„æ‡’æƒ° 
https://x.com/0xSunNFT/status/1913608106275397829
â€¦2025.05.01 $Gorkè·åˆ©18ä¸‡u 
https://x.com/0xSunNFT/status/1917685646409490783
â€¦ 2025.05.31 è®¤ä¸ºå¤§éƒ¨åˆ†å±±å¯¨å·²ç»é‡æ–°è¿›å…¥ä¸‹è·Œè¶‹åŠ¿
https://x.com/0xSunNFT/status/1928769488146804791
â€¦ 2025.07.08 PumpFunå…¬å”®æ˜¯æœºä¼š 
https://x.com/0xSunNFT/status/1942314375051960807
â€¦ 2025.07.23 é“¾ä¸ŠMemeä¸¤å¤§æ–¹æ³•è®ºï¼Œå™äº‹äº¤æ˜“å’Œåœ°å€æŒ–æ˜ 
https://x.com/0xSunNFT/status/1948021791487824032
â€¦ 2025.08.01 åšå¤šETHï¼Œåšç©ºå±±å¯¨å¸å¯¹å†²
https://x.com/0xSunNFT/status/1951099879906058707
â€¦ 2025.09.02 å¤ç›˜åšç©ºWLFIè·åˆ©$1M 
https://x.com/0xSunNFT/status/1962792706905915473
"""

# ==================== é…ç½®åŒºåŸŸ ====================
# ä»£ç†é…ç½®ï¼ˆå¦‚æœä¸éœ€è¦ä»£ç†ï¼Œè®¾ç½®ä¸ºNoneï¼‰
PROXY = "http://127.0.0.1:7890"  # é»˜è®¤ä»£ç†åœ°å€ï¼Œå¯ä»¥è®¾ç½®ä¸ºNoneç¦ç”¨

# æ˜¯å¦ä½¿ç”¨æŒä¹…åŒ–Profileï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œéœ€è¦æ‰‹åŠ¨ç™»å½•ï¼Œä¹‹åä¼šä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
USE_PERSISTENT_PROFILE = True
PROFILE_DIR = "./chrome_profile"

# å·²æŠ“å–æ¨æ–‡IDè®°å½•æ–‡ä»¶ï¼ˆé¿å…é‡å¤æŠ“å–ï¼‰
SCRAPED_IDS_FILE = "scraped_tweet_ids.json"

# ==================== è¾…åŠ©å‡½æ•° ====================
def load_scraped_ids():
    """åŠ è½½å·²æŠ“å–çš„æ¨æ–‡ID"""
    if os.path.exists(SCRAPED_IDS_FILE):
        try:
            with open(SCRAPED_IDS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_scraped_id(tweet_id):
    """ä¿å­˜å·²æŠ“å–çš„æ¨æ–‡ID"""
    scraped_ids = load_scraped_ids()
    scraped_ids.add(tweet_id)
    with open(SCRAPED_IDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(scraped_ids), f, indent=2)

def random_sleep(min_sec=3, max_sec=7):
    """éšæœºå»¶æ—¶ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
    sleep_time = random.uniform(min_sec, max_sec)
    print(f"  éšæœºç­‰å¾… {sleep_time:.2f} ç§’...")
    time.sleep(sleep_time)

def simulate_human_scroll(driver):
    """æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º"""
    print("  æ¨¡æ‹Ÿé¡µé¢æ»šåŠ¨...")
    scroll_times = random.randint(1, 3)
    for _ in range(scroll_times):
        scroll_amount = random.randint(200, 500)
        driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        time.sleep(random.uniform(0.5, 1.5))

def create_undetected_driver():
    """åˆ›å»ºåæ£€æµ‹çš„Chromeæµè§ˆå™¨å®ä¾‹"""
    print("æ­£åœ¨å¯åŠ¨ undetected_chromedriver...")
    
    options = uc.ChromeOptions()
    
    # æ·»åŠ ä»£ç†é…ç½®
    if PROXY:
        print(f"  é…ç½®ä»£ç†: {PROXY}")
        options.add_argument(f'--proxy-server={PROXY}')
    
    # ä½¿ç”¨æŒä¹…åŒ–Profile
    if USE_PERSISTENT_PROFILE:
        print(f"  ä½¿ç”¨æŒä¹…åŒ–Profile: {PROFILE_DIR}")
        options.add_argument(f'--user-data-dir={PROFILE_DIR}')
    
    # å…¶ä»–ä¼˜åŒ–é€‰é¡¹
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    
    try:
        driver = uc.Chrome(options=options)
        print("âœ“ undetected_chromedriver å¯åŠ¨æˆåŠŸ")
        return driver
    except Exception as e:
        print(f"Ã— å¯åŠ¨å¤±è´¥: {e}")
        print("\nè¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆ:")
        print("1. å®‰è£…undetected-chromedriver: pip install undetected-chromedriver")
        print("2. ç¡®ä¿Chromeæµè§ˆå™¨å·²å®‰è£…")
        print("3. å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£å¸¸è¿è¡Œ")
        raise

# ==================== ä¸»ç¨‹åº ====================

# 1. ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æ¨æ–‡URL
tweet_urls = re.findall(r'https://x\.com/\w+/status/\d+', original_text)
print(f"æ£€æµ‹åˆ° {len(tweet_urls)} æ¡æ¨æ–‡é“¾æ¥ã€‚")

# åŠ è½½å·²æŠ“å–çš„æ¨æ–‡ID
scraped_ids = load_scraped_ids()
print(f"å·²æŠ“å–çš„æ¨æ–‡æ•°: {len(scraped_ids)}")

# 2. åˆå§‹åŒ–Selenium WebDriver
print("\næ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
driver = create_undetected_driver()

try:
    # 3. æ£€æŸ¥ç™»å½•çŠ¶æ€
    driver.get("https://x.com/home")
    time.sleep(3)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
    current_url = driver.current_url
    if "login" in current_url or "i/flow/login" in current_url:
        print("\n" + "="*50)
        print("æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
        print("æµè§ˆå™¨å·²æ‰“å¼€ç™»å½•é¡µé¢ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­æ‰‹åŠ¨ç™»å½•ä½ çš„Xè´¦å·ã€‚")
        print("ç™»å½•æˆåŠŸåï¼Œå›åˆ°è¿™é‡Œï¼ŒæŒ‰Enteré”®ç»§ç»­æ‰§è¡ŒæŠ“å–...")
        print("æ³¨æ„ï¼šç™»å½•ä¿¡æ¯å°†ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶æ— éœ€é‡å¤ç™»å½•")
        print("="*50)
        input() # ç­‰å¾…ç”¨æˆ·æŒ‰Enteré”®
    else:
        print("\nâœ“ æ£€æµ‹åˆ°å·²ç™»å½•çŠ¶æ€ï¼Œæ— éœ€é‡å¤ç™»å½•")
        print("æç¤ºï¼šå¦‚éœ€åˆ‡æ¢è´¦å·ï¼Œè¯·åˆ é™¤ chrome_profile ç›®å½•åé‡æ–°è¿è¡Œ")

    print("\nå¼€å§‹æŠ“å–æ¨æ–‡å†…å®¹...\n")
    
    all_tweets_data = []

    # 4. åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    images_dir = f"tweets_images_{timestamp}"
    os.makedirs(images_dir, exist_ok=True)
    
    # 5. å¾ªç¯è®¿é—®æ¯ä¸ªURLå¹¶æŠ“å–å†…å®¹
    for i, url in enumerate(tweet_urls):
        # æå–æ¨æ–‡ID
        tweet_id = url.split('/')[-1]
        
        # æ£€æŸ¥æ˜¯å¦å·²æŠ“å–
        if tweet_id in scraped_ids:
            print(f"--- è·³è¿‡ç¬¬ {i+1}/{len(tweet_urls)} æ¡ï¼ˆå·²æŠ“å–ï¼‰: {url} ---")
            continue
            
        print(f"--- æ­£åœ¨æŠ“å–ç¬¬ {i+1}/{len(tweet_urls)} æ¡: {url} ---")
        try:
            driver.get(url)
            
            # ç­‰å¾…æ¨æ–‡å†…å®¹åŠ è½½å‡ºæ¥
            wait = WebDriverWait(driver, 15)
            tweet_article = wait.until(
                EC.presence_of_element_located((By.XPATH, "//article[@data-testid='tweet']"))
            )
            
            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º
            simulate_human_scroll(driver)
            
            # æå–æ¨æ–‡æ­£æ–‡
            try:
                tweet_text_element = tweet_article.find_element(By.XPATH, ".//div[@data-testid='tweetText']")
                tweet_text = tweet_text_element.text
            except NoSuchElementException:
                tweet_text = ""
            
            # æå–ç”¨æˆ·åï¼ˆ@handleï¼‰
            try:
                user_handle_element = tweet_article.find_element(By.XPATH, ".//div[@data-testid='User-Name']//a[contains(@href, '/')]")
                user_handle = user_handle_element.get_attribute('href').split('/')[-1]
                user_handle = f"@{user_handle}"
            except NoSuchElementException:
                user_handle = ""
            
            # æå–æ¨æ–‡æ—¶é—´
            tweet_time = ""
            try:
                time_element = tweet_article.find_element(By.XPATH, ".//time")
                tweet_time = time_element.get_attribute('datetime')
                # æ ¼å¼åŒ–æ—¶é—´ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                if tweet_time:
                    dt = datetime.fromisoformat(tweet_time.replace('Z', '+00:00'))
                    tweet_time = dt.strftime('%Y-%m-%d %H:%M:%S')
            except NoSuchElementException:
                pass
            

            # æå–å›¾ç‰‡ï¼ˆæ–°æ–¹æ³•ï¼šç›´æ¥ä»ç¼©ç•¥å›¾URLæ¨å¯¼åŸå›¾ï¼‰
            image_urls = []
            try:
                # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«å›¾ç‰‡çš„ div å…ƒç´ 
                photo_divs = tweet_article.find_elements(By.XPATH, ".//div[@data-testid='tweetPhoto']")
                
                # éå†æ¯ä¸ªå›¾ç‰‡å…ƒç´ ï¼Œæå–å…¶ src
                for photo_div in photo_divs:
                    # åœ¨æ¯ä¸ª div ä¸­æ‰¾åˆ° img æ ‡ç­¾
                    img_elements = photo_div.find_elements(By.TAG_NAME, "img")
                    for img_element in img_elements:
                        img_url = img_element.get_attribute('src')
                        
                        if img_url:
                            # å°†URLå‚æ•°æ›¿æ¢ä¸º 'name=orig' æ¥è·å–æœ€é«˜æ¸…çš„åŸå›¾
                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç¡®ä¿æ›¿æ¢çš„å‡†ç¡®æ€§
                            if 'name=' in img_url:
                                orig_img_url = re.sub(r'name=\w+', 'name=orig', img_url)
                            else:
                                # å¦‚æœURLä¸­æ²¡æœ‰ name å‚æ•°ï¼Œå¯èƒ½éœ€è¦æ·»åŠ  format=...&name=orig
                                # ä½†é€šå¸¸ç›´æ¥åœ¨æœ«å°¾æ·»åŠ  ?name=orig ä¹Ÿèƒ½å¥æ•ˆ
                                orig_img_url = img_url.split('?')[0] + '?format=jpg&name=orig'
                            
                            if orig_img_url not in image_urls:
                                image_urls.append(orig_img_url)
                                
                                # ä¸‹è½½å›¾ç‰‡
                                try:
                                    # ä»URLä¸­æå–æ–‡ä»¶åå’Œæ‰©å±•å
                                    file_name_part = orig_img_url.split('/')[-1].split('?')[0]
                                    ext_match = re.search(r'format=(\w+)', orig_img_url)
                                    ext = ext_match.group(1) if ext_match else 'jpg'
                                    
                                    img_filename = f"{file_name_part}.{ext}"
                                    img_path = os.path.join(images_dir, img_filename)

                                    # ä½¿ç”¨å¸¦æœ‰ User-Agent çš„ requests session æ¥ä¸‹è½½
                                    session = requests.Session()
                                    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
                                    img_response = session.get(orig_img_url, headers=headers, timeout=15)
                                    
                                    if img_response.status_code == 200:
                                        with open(img_path, 'wb') as f:
                                            f.write(img_response.content)
                                        print(f"  âœ“ å·²ä¿å­˜å›¾ç‰‡: {img_filename}")
                                    else:
                                        print(f"  Ã— ä¸‹è½½å›¾ç‰‡å¤±è´¥ (çŠ¶æ€ç : {img_response.status_code})")
                                except Exception as download_error:
                                    print(f"  Ã— ä¸‹è½½å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {download_error}")

            except NoSuchElementException:
                pass  # è¯¥æ¨æ–‡æ²¡æœ‰å›¾ç‰‡

            
            print(f"ç”¨æˆ·å: {user_handle}")
            print(f"å‘å¸ƒæ—¶é—´: {tweet_time}")
            print(f"å†…å®¹:\n{tweet_text}")
            print(f"å›¾ç‰‡æ•°é‡: {len(image_urls)}\n")
            
            # å°†æŠ“å–çš„æ•°æ®å­˜èµ·æ¥
            all_tweets_data.append({
                "url": url,
                "handle": user_handle,
                "time": tweet_time,
                "text": tweet_text,
                "images": image_urls,
                "image_count": len(image_urls)
            })
            
            # ä¿å­˜å·²æŠ“å–çš„æ¨æ–‡ID
            save_scraped_id(tweet_id)
            
            # éšæœºæ‰§è¡Œä¸€äº›"æ„å¤–"æ“ä½œï¼ˆ5%æ¦‚ç‡ï¼‰
            if random.random() < 0.05:
                action = random.choice(['refresh', 'scroll_top', 'mouse_move'])
                if action == 'refresh':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] åˆ·æ–°é¡µé¢...")
                    driver.refresh()
                    time.sleep(random.uniform(2, 4))
                elif action == 'scroll_top':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨...")
                    driver.execute_script("window.scrollTo(0, 0);")
                    time.sleep(random.uniform(1, 2))
                elif action == 'mouse_move':
                    print("  [æ¨¡æ‹Ÿè¡Œä¸º] éšæœºç§»åŠ¨é¼ æ ‡...")
                    try:
                        actions = ActionChains(driver)
                        actions.move_by_offset(random.randint(50, 200), random.randint(50, 200))
                        actions.perform()
                    except:
                        pass

            # éšæœºå»¶æ—¶ï¼Œæ¨¡ä»¿äººç±»è¡Œä¸ºï¼Œé™ä½è¢«å°é”çš„é£é™©
            random_sleep(3, 7)

        except Exception as e:
            print(f"æŠ“å–å¤±è´¥: {url}\né”™è¯¯ä¿¡æ¯: {e}\n")
            # å³ä½¿å¤±è´¥ä¹Ÿéšæœºç­‰å¾…ä¸€ä¸‹
            time.sleep(random.uniform(2, 4))
            continue

finally:
    # 5. å…³é—­æµè§ˆå™¨
    print("æ‰€æœ‰æŠ“å–ä»»åŠ¡å®Œæˆï¼Œå…³é—­æµè§ˆå™¨ã€‚")
    driver.quit()

# 6. ä¿å­˜æ•°æ®åˆ°CSVå’ŒMarkdownæ–‡ä»¶
if all_tweets_data:
    csv_filename = f"tweets_data_{timestamp}.csv"
    md_filename = f"tweets_data_{timestamp}.md"
    
    # ä¿å­˜CSVæ–‡ä»¶
    print(f"\nå¼€å§‹ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶: {csv_filename}")
    with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        fieldnames = ['åºå·', 'ç”¨æˆ·å', 'å‘å¸ƒæ—¶é—´', 'æ¨æ–‡é“¾æ¥', 'æ¨æ–‡å†…å®¹', 'å›¾ç‰‡æ•°é‡', 'å›¾ç‰‡URL']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # å†™å…¥è¡¨å¤´
        writer.writeheader()
        
        # å†™å…¥æ•°æ®
        for idx, tweet in enumerate(all_tweets_data, 1):
            # å°†å›¾ç‰‡URLåˆ—è¡¨è½¬ä¸ºå­—ç¬¦ä¸²
            images_str = '; '.join(tweet['images']) if tweet['images'] else ''
            
            writer.writerow({
                'åºå·': idx,
                'ç”¨æˆ·å': tweet['handle'],
                'å‘å¸ƒæ—¶é—´': tweet['time'],
                'æ¨æ–‡é“¾æ¥': tweet['url'],
                'æ¨æ–‡å†…å®¹': tweet['text'],
                'å›¾ç‰‡æ•°é‡': tweet['image_count'],
                'å›¾ç‰‡URL': images_str
            })
    
    print(f"âœ“ æˆåŠŸä¿å­˜ {len(all_tweets_data)} æ¡æ¨æ–‡æ•°æ®åˆ° {csv_filename}")
    
    # ä¿å­˜Markdownæ–‡ä»¶
    print(f"\nå¼€å§‹ç”ŸæˆMarkdownæ–‡æ¡£: {md_filename}")
    with open(md_filename, 'w', encoding='utf-8') as mdfile:
        # å†™å…¥æ ‡é¢˜
        mdfile.write(f"# æ¨æ–‡åˆé›†\n\n")
        mdfile.write(f"**æŠ“å–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        mdfile.write(f"**æ¨æ–‡æ€»æ•°**: {len(all_tweets_data)} æ¡\n\n")
        mdfile.write("---\n\n")
        
        # å†™å…¥æ¯æ¡æ¨æ–‡
        for idx, tweet in enumerate(all_tweets_data, 1):
            mdfile.write(f"## {idx}. æ¨æ–‡ - {tweet['handle']}\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            mdfile.write(f"**å‘å¸ƒæ—¶é—´**: {tweet['time']}\n\n")
            mdfile.write(f"**æ¨æ–‡é“¾æ¥**: [{tweet['url']}]({tweet['url']})\n\n")
            
            # æ¨æ–‡å†…å®¹
            if tweet['text']:
                mdfile.write(f"**å†…å®¹**:\n\n")
                # å¤„ç†æ¨æ–‡å†…å®¹ä¸­çš„æ¢è¡Œï¼Œä½¿å…¶åœ¨Markdownä¸­æ­£ç¡®æ˜¾ç¤º
                content_lines = tweet['text'].split('\n')
                for line in content_lines:
                    if line.strip():
                        mdfile.write(f"{line}\n\n")
                    else:
                        mdfile.write("\n")
            
            # å›¾ç‰‡
            if tweet['images']:
                mdfile.write(f"**å›¾ç‰‡** ({len(tweet['images'])} å¼ ):\n\n")
                for img_idx, img_url in enumerate(tweet['images'], 1):
                    # æœ¬åœ°å›¾ç‰‡è·¯å¾„
                    local_img = f"{images_dir}/tweet_{idx}_img_{img_idx}.jpg"
                    if os.path.exists(local_img):
                        mdfile.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    elif os.path.exists(local_img.replace('.jpg', '.png')):
                        local_img = local_img.replace('.jpg', '.png')
                        mdfile.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    elif os.path.exists(local_img.replace('.jpg', '.gif')):
                        local_img = local_img.replace('.jpg', '.gif')
                        mdfile.write(f"![å›¾ç‰‡ {img_idx}]({local_img})\n\n")
                    
                    # åŒæ—¶ä¿ç•™åŸå§‹URLé“¾æ¥
                    mdfile.write(f"*åŸå›¾é“¾æ¥*: [{img_url}]({img_url})\n\n")
                    mdfile.write(f"![image]({img_url})\n\n")
            
            mdfile.write("---\n\n")
    
    print(f"âœ“ æˆåŠŸç”ŸæˆMarkdownæ–‡æ¡£ {md_filename}")
    print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
    print(f"  - CSVæ–‡ä»¶: {csv_filename}")
    print(f"  - Markdownæ–‡æ¡£: {md_filename}")
    print(f"  - å›¾ç‰‡ç›®å½•: {images_dir}/")
    print(f"  - æ¨æ–‡æ€»æ•°: {len(all_tweets_data)}")
    
    # ç»Ÿè®¡å›¾ç‰‡æ€»æ•°
    total_images = sum(tweet['image_count'] for tweet in all_tweets_data)
    print(f"  - å›¾ç‰‡æ€»æ•°: {total_images}")
    
else:
    print("\næœªæŠ“å–åˆ°ä»»ä½•æ¨æ–‡æ•°æ®,æœªç”Ÿæˆæ–‡ä»¶ã€‚")